{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5aa199e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras as keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Conv1D, Flatten, Dropout, GRU, Input, SimpleRNN\n",
    "from tensorflow.keras.layers import AveragePooling1D, MaxPool1D, GlobalMaxPool1D, AveragePooling1D, GlobalAveragePooling1D\n",
    "\n",
    "import pickle\n",
    "from keras_pickle_wrapper import KerasPickleWrapper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "STOPWORDS = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6468e69a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16675666159517920964\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5077532672\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11129327609517771562\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d533827b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label                                           Headline\n",
      "0      0  Employer who stole nearly $3M in wages from 15...\n",
      "1      1  Huge new Facebook data leak exposed intimate d...\n",
      "2      0  A campaign has accelerated to turn a disused r...\n",
      "3      1  Google launches global human trafficking helpl...\n",
      "4      1  Over 3m Saudi Women Donâ€™t Have ID Cards; Saudi...\n"
     ]
    }
   ],
   "source": [
    "news1 = pd.read_csv('./data/djia_news copy.csv')\n",
    "news2 = pd.read_csv('./data/nasdaq.csv')\n",
    "combined_news = news1.append(news2)\n",
    "combined_news = combined_news[['Label', 'Headline']]\n",
    "\n",
    "print(combined_news.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c92d2cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps = PorterStemmer()\n",
    "# lamatizer = WordNetLemmatizer()\n",
    "# combined_news['Headline'] = combined_news['Headline'].replace('[^\\s\\w]', '')\n",
    "# combined_news['Headline_token'] = combined_news['Headline'].apply(lambda x: word_tokenize(x))\n",
    "# combined_news['Headline_recon'] = combined_news['Headline_token'].apply(lambda x: list(ps.stem(i) for i in x))\n",
    "# combined_news['Headline_recon'] = combined_news['Headline_recon'].apply(lambda x: ' '.join(list(i for i in x if i not in STOPWORDS)))\n",
    "# print(combined_news['Headline_recon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86142d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9995\n",
       "1    5236\n",
       "2     331\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_news['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc95edd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9995, 2) (5236, 2) (331, 2)\n"
     ]
    }
   ],
   "source": [
    "#Resampling due to imbalanced dataset\n",
    "class_count_0, class_count_1, class_count_2 = combined_news['Label'].value_counts()\n",
    "\n",
    "#Seperating the classes\n",
    "class_0 = combined_news[combined_news['Label'] == 0]\n",
    "class_1 = combined_news[combined_news['Label'] == 1]\n",
    "class_2 = combined_news[combined_news['Label'] == 2]\n",
    "print(class_0.shape, class_1.shape, class_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71af8e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Random Under Sampling\n",
    "# class_0_under = class_0.sample(class_count_2)\n",
    "# class_1_under = class_1.sample(class_count_2)\n",
    "\n",
    "# train_under = pd.concat([class_0_under, class_1_under, class_2], axis = 0)\n",
    "\n",
    "# train_under['Label'].value_counts().plot(kind = 'bar', title = 'count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8467caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Random Over Sampling\n",
    "# class_2_over = class_2.sample(class_count_0, replace = True)\n",
    "\n",
    "# train_over = pd.concat([class_0, class_1, class_2_over], axis = 0)\n",
    "# train_over['Label'].value_counts().plot(kind = 'bar', title = 'count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbbf12a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting neutral data from another dataset\n",
    "news3 = pd.read_csv('./data/train.csv')\n",
    "news3 = news3[news3['Label'] == 'neutral']\n",
    "news3 = news3.sample(class_count_0)\n",
    "news3['Label'] = news3['Label'].replace('neutral', 2)\n",
    "combined_news = combined_news.append(news3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fd6e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_news['Headline'] = combined_news['Headline'].astype(str)\n",
    "combined_news['Label'] = combined_news['Label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f01f751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    10326\n",
       "0     9995\n",
       "1     5236\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_news['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14fafedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is important for splitting a one column classification to an n-column classification\n",
    "y = pd.get_dummies(combined_news['Label'])\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b155018",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, test_text, train_labels, test_labels = train_test_split(combined_news['Headline'].to_numpy(), y.to_numpy(), test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3a32a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5112 20445\n"
     ]
    }
   ],
   "source": [
    "print(len(test_text),len(train_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edabb31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b691107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "emb_size = 300\n",
    "max_length = 20000\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<oov>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5472eb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1f36dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for i in range(0, len(train_text)):\n",
    "    temp = train_text[i]\n",
    "    temp = re.sub('@\\S+', '', temp)\n",
    "    temp = re.sub('https*\\S+', '', temp)\n",
    "    temp = re.sub('#\\S+', '', temp)\n",
    "    temp = re.sub(\"[^\\s\\w]\", '', temp)\n",
    "    temp = re.sub(\"\\'\\w+\", '', temp)\n",
    "    temp = re.sub(r'\\w*\\d+\\w*', '', temp)\n",
    "    temp = re.sub('\\s{2,}', '', temp)\n",
    "    \n",
    "    temp = temp.split()\n",
    "    \n",
    "    temp = [stemmer.lemmatize(word) for word in temp]\n",
    "    temp = ' '.join(temp)\n",
    "    train_text[i] = temp\n",
    "\n",
    "for i in range(0, len(test_text)):\n",
    "    temp = train_text[i]\n",
    "    temp = re.sub('@\\S+:', '', temp)\n",
    "    temp = re.sub('https*\\S+', '', temp)\n",
    "    temp = re.sub(\"[^\\s\\w]\", '', temp)\n",
    "    temp = re.sub('#\\S+', '', temp)\n",
    "    temp = re.sub(\"\\'\\w+\", '', temp)\n",
    "    temp = re.sub(r'\\w*\\d+\\w*', '', temp)\n",
    "    temp = re.sub('\\s{2,}', '', temp)\n",
    "    temp = temp.split()\n",
    "    \n",
    "    temp = [stemmer.lemmatize(word) for word in temp]\n",
    "    temp = ' '.join(temp)\n",
    "    test_text[i] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28d8d6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20439, 5111)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtered_train_text = []\n",
    "# for w in range(0, len(train_text)):\n",
    "#     if train_text[w] not in STOPWORDS:\n",
    "#         filtered_train_text.append(train_text[w])\n",
    "\n",
    "# filtered_test_text = []\n",
    "# for w in range(0, len(test_text)):\n",
    "#     if test_text[w] not in STOPWORDS:\n",
    "#         filtered_test_text.append(test_text[w])\n",
    "\n",
    "# len(filtered_train_text), len(filtered_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72a5ddaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33775\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(train_text)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(len(word_index))\n",
    "\n",
    "train_sequences =  tokenizer.texts_to_sequences(train_text)\n",
    "train_padded = pad_sequences(train_sequences, maxlen = max_length, padding = padding_type, truncating = trunc_type)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(test_text)\n",
    "test_padded = pad_sequences(test_sequences, maxlen = max_length, padding = padding_type, truncating = trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45297be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26349e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f25dd837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_embed = embed(train_text)\n",
    "# test_embed = embed(test_text)\n",
    "# len(train_embed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7adbb72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Another embedding method\n",
    "# embedding_index = {}\n",
    "# glove_file = open('./glove.6B.300d.txt', encoding=\"utf8\")\n",
    "# for line in glove_file:\n",
    "#     data = line.split()\n",
    "#     word = data[0]\n",
    "#     vector = np.asarray(data[1:], dtype = 'float32')\n",
    "#     embedding_index[word] = vector\n",
    "# glove_file.close()\n",
    "\n",
    "# len(embedding_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d264f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_matrix = np.zeros((len(word_index) + 1, emb_size))\n",
    "# for word in word_index.items():\n",
    "#     embedding_vector = embedding_index.get(word)\n",
    "#     if embedding_vector is not None:\n",
    "#         embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# embedding_matrix.shape\n",
    "# embedding_matrix = embedding_matrix[:vocab_size][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "508c12ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 20000, 300)        3000000   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               154112    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 3,333,523\n",
      "Trainable params: 3,333,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, emb_size,input_length = max_length))\n",
    "model.add(LSTM(16,return_sequences= True))\n",
    "model.add(Bidirectional(LSTM(16,return_sequences= True)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(3,activation = 'softmax'))\n",
    "          \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85db640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f57cf861",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20445 samples, validate on 5112 samples\n",
      "Epoch 1/4\n",
      "20445/20445 [==============================] - 219s 11ms/sample - loss: 0.6017 - accuracy: 0.7153 - val_loss: 3.1708 - val_accuracy: 0.3995\n",
      "Epoch 2/4\n",
      "20445/20445 [==============================] - 219s 11ms/sample - loss: 0.4356 - accuracy: 0.7807 - val_loss: 4.3779 - val_accuracy: 0.3599\n",
      "Epoch 3/4\n",
      "20445/20445 [==============================] - 218s 11ms/sample - loss: 0.3375 - accuracy: 0.8532 - val_loss: 4.7966 - val_accuracy: 0.3550\n",
      "Epoch 4/4\n",
      " 1120/20445 [>.............................] - ETA: 3:05 - loss: 0.2012 - accuracy: 0.9338"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-e3f7d0f57fe4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                         \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                         \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                         validation_data = (test_padded, test_labels))\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    history = model.fit(train_padded,\n",
    "                        train_labels,\n",
    "                        shuffle = True,\n",
    "                        epochs = 4,\n",
    "                        validation_data = (test_padded, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21ee9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_' + metric])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_' + metric])\n",
    "    plt.show()\n",
    "plot_metrics(history, 'accuracy')\n",
    "plot_metrics(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c66dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from keras_pickle_wrapper import KerasPickleWrapper\n",
    "\n",
    "pickled_wrapped = KerasPickleWrapper(model)\n",
    "filename = './model_weight.pkl'\n",
    "pickle.dump(pickled_wrapped, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
